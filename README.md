# Speech-Emotion-Recognition

* In this project I have used CREMA-D dataset which is consist of 7,442 original clips from 91 actors. Actors spoke from a selection of 12 sentences. The                sentences were presented using one of six different emotions (Anger, Disgust, Fear, Happy, Neutral, and Sad).

* Convolutional Neural Network (CNN) is used to train and predict emotions using speech data which was transformed using Librosa library.

* After training the model, I made web app for model using flask microframework and deployed it locally.

* Here are screenshots of web app of the model,
## input page:

![Screenshot (128)](https://user-images.githubusercontent.com/105780030/179716358-569af9c5-df0f-42be-8025-ea9707e6960e.png)

![Screenshot (127)](https://user-images.githubusercontent.com/105780030/179716404-94a18a3b-4e90-4865-b2c8-5d06590246e8.png)

## output pages:
### output page with happy emotion:
![Screenshot (121)](https://user-images.githubusercontent.com/105780030/179715496-6ef07602-5084-41d3-b42e-4650955138ad.png)

### output page with angry emotion:
![Screenshot (125)](https://user-images.githubusercontent.com/105780030/179715635-debd98e5-0652-4e1b-b3fe-b1d27d066d6b.png)

### output page with sad emotion:
![Screenshot (126)](https://user-images.githubusercontent.com/105780030/179715717-d182f8a1-3672-49ef-a0c9-be693e1fac9f.png)

### output page with neutral emotion:
![Screenshot (122)](https://user-images.githubusercontent.com/105780030/179715801-de35e2a2-a8b2-4cca-98e1-b77d8c902b38.png)

### output page with disgust emotion:
![Screenshot (124)](https://user-images.githubusercontent.com/105780030/179715865-e0d1cedf-87f6-414d-9fe3-ca66ffe6395d.png)

### output page with fear emotion:
![Screenshot (123)](https://user-images.githubusercontent.com/105780030/179715909-7894b9c2-a500-44f3-81e6-6e14af3692f8.png)
